
https://chrisalbon.com/machine-learning/feature_selection_using_random_forest.html
http://www.techpoweredmath.com/spark-dataframes-mllib-tutorial/#.Wh3bzlWnGpo
https://github.com/jakevdp/ESAC-stats-2014/blob/master/notebooks/04.2-Regression-Forests.ipynb
Feature importance -> https://stackoverflow.com/questions/28971989/pyspark-mllib-random-forest-feature-importances

Random forest- comparison
http://fastml.com/what-is-better-gradient-boosted-trees-or-random-forest/

mkdir -p data
curl https://www.quandl.com/api/v3/datasets/BCHARTS/COINBASEUSD.csv?api_key=3ny-RLKDcGxjRDxRco8J >>data/Bitcoin_USD_History.csv
curl https://www.quandl.com/api/v3/datasets/BCHARTS/COINBASEGBP.csv?api_key=3ny-RLKDcGxjRDxRco8J >>data/Bitcoin_GBP_History.csv
curl https://www.quandl.com/api/v3/datasets/BCHARTS/COINBASEEUR.csv?api_key=3ny-RLKDcGxjRDxRco8J >>data/Bitcoin_EUR_History.csv

+++++++++++++++++++++++++++++++++++++++++++++++
from pyspark.sql.types import *
from pyspark.sql import Row
from datetime import datetime

import pyspark.mllib
import pyspark.mllib.regression
from pyspark.mllib.regression import LabeledPoint
from pyspark.sql.functions import *

data=sc.textFile('/idn/home/akuppura/learn/bit.tsv')
rdd = data.map(lambda line: line.split("\t"))
rdd.take(10)

df = rdd.map(lambda line: Row(Open = line[1], volume=line[5],weekday=datetime.strptime(line[0],"%y%m%d").date().weekday())).toDF()
temp = df.map(lambda line:LabeledPoint(line[0],[line[1:]]))
temp.take(5)
(trainingData, testData) = temp.randomSplit([0.9, 0.1])


model = RandomForest.trainRegressor(trainingData, categoricalFeaturesInfo={},numTrees=10, featureSubsetStrategy="auto",impurity='variance', maxDepth=4, maxBins=32)
predictions = model.predict(testData.map(lambda x: x.features))
labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)
testMSE = labelsAndPredictions.map(lambda lp: (lp[0] - lp[1]) * (lp[0] - lp[1])).sum() /\
    float(testData.count())
print('Test Mean Squared Error = ' + str(testMSE))
print('Learned regression forest model:')
print(model.toDebugString())


model = GradientBoostedTrees.trainClassifier(trainingData,categoricalFeaturesInfo={}, numIterations=3)
predictions = model.predict(testData.map(lambda x: x.features))
labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)
testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(testData.count())
print('Test Error = ' + str(testErr))
